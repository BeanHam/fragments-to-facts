{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ca44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binhan/anaconda3/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from together import Together\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from utils import *\n",
    "from huggingface_hub import login as hf_login\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from datasets import concatenate_datasets, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b821c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/binhan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open('model_map.json') as f:\n",
    "    model_map=json.load(f)\n",
    "key = '779d92de61a5035835e5023ca79e2e5b6124c6300c3ceb0e07e374f948554116'\n",
    "client = Together(api_key=key)\n",
    "hf_login(token=\"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\")\n",
    "dataset = load_dataset(\"beanham/medsum_llm_attack\")\n",
    "merged_dataset = concatenate_datasets([dataset['train'], dataset['validation'], dataset['test']])\n",
    "new_ids = range(len(merged_dataset))\n",
    "merged_dataset = merged_dataset.add_column(\"new_ID\", new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "split='train'\n",
    "id='2'\n",
    "\n",
    "## load model\n",
    "target_model_api_key=model_map[split+'_'+id]['model_id']\n",
    "prob_generator = GenerateNextTokenProbAPI(client, target_model_api_key)\n",
    "\n",
    "## load data\n",
    "target_subsample_ids = pd.read_csv(f\"formatted_data/subsample_ids_{id}.csv\")['new_ID'].tolist()\n",
    "train_dataset = merged_dataset.filter(lambda example: example['new_ID'] in target_subsample_ids)\n",
    "test_dataset = merged_dataset.filter(lambda example: example['new_ID'] not in target_subsample_ids)\n",
    "\n",
    "## why are we only using len(ents)<5 as the unseen ents?\n",
    "unseen_ents = [sample['disease_ents'] for sample in test_dataset if len(sample['disease_ents']) < 5]\n",
    "unseen_ents = [item for sublist in unseen_ents for item in sublist]\n",
    "train_dataset = [sample for sample in train_dataset if len(sample['disease_ents']) >= 5]\n",
    "test_dataset = [sample for sample in test_dataset if len(sample['disease_ents']) >= 5]\n",
    "train_test_ents = {'train': train_dataset,'test': test_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14024df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "fail_counter = 0\n",
    "# get first 50 pairs from train_test_ents \n",
    "\n",
    "for name, samples in train_test_ents.items():\n",
    "    #print(f\"running {name}\")\n",
    "    \n",
    "    for ent_list in samples[:5]:\n",
    "        #print(f\"running {ent_list}\")\n",
    "        \n",
    "        ## create saving dictionary\n",
    "        key=name+'_'+str(ent_list['ID'])\n",
    "        results[key]={}\n",
    "        results[key]['y_stars']={}\n",
    "        results[key]['y_NON_stars']={}        \n",
    "        ents = list(set(ent_list['disease_ents']))\n",
    "        k = len(ents)\n",
    "        unseen_ents_for_sample = random.sample(unseen_ents, k)\n",
    "        \n",
    "        ## go through each y_star\n",
    "        for i in tqdm(range(k)):\n",
    "            \n",
    "            y_star = ents[i]\n",
    "            y_NON_star = unseen_ents_for_sample[i]\n",
    "            results[key]['y_stars'][y_star]={}\n",
    "            results[key]['y_NON_stars'][y_NON_star]={}                        \n",
    "            remaining_ents = ents[:i] + ents[i + 1:]            \n",
    "            \n",
    "            # prompt = f\"consider someone with the following conditions: {', '.join(remaining_ents)}. the individual then also has the condition \"\n",
    "            prompt_start = PROMPT_TEMPLATE[PROMPT_TO_USE][0]\n",
    "            prompt_end = PROMPT_TEMPLATE[PROMPT_TO_USE][1]\n",
    "            ents_string = ', '.join(remaining_ents)\n",
    "            prompt = f\"{prompt_start} {ents_string} {prompt_end}\"\n",
    "\n",
    "            #print(prompt)\n",
    "\n",
    "            prob = compute_token_probs_api(y_star, prompt, prob_generator) \n",
    "            prob_NON = compute_token_probs_api(y_NON_star, prompt, prob_generator)            \n",
    "            if prob == -1 or prob_NON == -1:\n",
    "                fail_counter += 1\n",
    "                print(f\"failed {fail_counter} times\")\n",
    "                continue            \n",
    "            results[key]['y_stars'][y_star]['target']=prob\n",
    "            results[key]['y_NON_stars'][y_NON_star]['target']=prob_NON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc621fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'target_token_probs_3_prompt_0_4_epochs.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

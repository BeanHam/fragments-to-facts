{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf9aaa3-969e-4127-a6b5-23be86027c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import makedirs, path\n",
    "from together import Together\n",
    "\n",
    "from utils import *\n",
    "from huggingface_hub import login as hf_login\n",
    "from datasets import concatenate_datasets, DatasetDict, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77189f2-aea7-4824-8a5b-cd9bdca88516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================================================================================\n",
      "Please deploy the following model bh193/Meta-Llama-3.1-8B-Instruct-Reference-12711f3e-e2f6d583. The deployment might take up to 10 mins. Once the model is deployed, please proceed...\n",
      "====================================================================================================================================================== \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------\n",
    "# Parameters\n",
    "#-------------------    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=str, default='formatted_data/')\n",
    "parser.add_argument('--model_tag', type=str, default='llama_10_epoch')\n",
    "parser.add_argument('--together_key', type=str)\n",
    "args = parser.parse_args(args=[])\n",
    "with open('model_map.json') as f:\n",
    "    model_map=json.load(f)\n",
    "client = Together(api_key=\"779d92de61a5035835e5023ca79e2e5b6124c6300c3ceb0e07e374f948554116\")\n",
    "target_model_api_key = model_map[args.model_tag]['train']['api_key']\n",
    "input(f\"\"\"\n",
    "======================================================================================================================================================\n",
    "Please deploy the following model {target_model_api_key}. The deployment might take up to 10 mins. Once the model is deployed, please proceed...\n",
    "======================================================================================================================================================\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3af1056e-12df-4aed-b383-d3b20467c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"You are a helpful medical assistant! Please help me summarize dialogues between doctors and patients.\"\n",
    "with open('formatted_data/llama_train.jsonl') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d1a991cb-d6b4-44fc-939c-6cef27347105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#-------------------------\n",
    "# memorization attack\n",
    "#-------------------------\n",
    "output=[]\n",
    "for i in tqdm(range(len(data[:10]))):\n",
    "    sample=data[i]\n",
    "    text=sample['text']\n",
    "    start_index=text.find(\"<|eot_id|><|start_header_id|>user<|end_header_id|>\")\n",
    "    end_index=text.find(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")\n",
    "    conv=text[start_index+50:end_index]+'\\n\\n'\n",
    "    prompt=text[end_index+55:]\n",
    "    \n",
    "    for prompt_length in [10,20,30]:\n",
    "        user=conv+' '.join(prompt.split()[:prompt_length])\n",
    "        gt=' '.join(prompt.split()[prompt_length:])\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user}\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=target_model_api_key,\n",
    "            messages=messages,\n",
    "            max_tokens=50,\n",
    "            temperature=0\n",
    "        )\n",
    "        output.append(['train_'+str(i), prompt_length, user, gt, response.choices[0].message.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b041d6c1-eac2-4562-8af2-71520e5a6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{args.model_tag}_memorization_attack_results.npy', output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

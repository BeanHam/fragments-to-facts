{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99377c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from together import Together\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7ee2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_world_model_probs_single(value, token_label, prompt, client, world_model_endpoints, is_star=True):\n",
    "    data_key = 'y_stars' if is_star else 'y_NON_stars'\n",
    "    \n",
    "    if 'world_models' not in value[data_key][token_label]:\n",
    "        value[data_key][token_label]['world_models'] = []\n",
    "        \n",
    "    #for wm_endpoint in tqdm(world_model_endpoints, desc=\"world model endpoints\", leave=False):\n",
    "    for wm_endpoint in world_model_endpoints:\n",
    "        wm_prob_gen = GenerateNextTokenProbAPI(client, wm_endpoint)\n",
    "        max_tokens=len(wm_prob_gen.tokenizer(prompt)['input_ids'])+10\n",
    "        wm_prob = compute_token_probs_api(token_label, prompt, wm_prob_gen, max_tokens)\n",
    "        value[data_key][token_label]['world_models'].append(float(wm_prob))\n",
    "\n",
    "def add_shadow_model_probs_single(value, token_label, prompt, client, shadow_model_endpoints, is_star=True):\n",
    "    data_key = 'y_stars' if is_star else 'y_NON_stars'\n",
    "    \n",
    "    if 'shadow_models' not in value[data_key][token_label]:\n",
    "        value[data_key][token_label]['shadow_models'] = []\n",
    "        \n",
    "    #for sm_endpoint in tqdm(shadow_model_endpoints, desc=\"shadow model endpoints\", leave=False):\n",
    "    for sm_endpoint in shadow_model_endpoints:\n",
    "        sm_prob_gen = GenerateNextTokenProbAPI(client, sm_endpoint)\n",
    "        max_tokens=len(sm_prob_gen.tokenizer(prompt)['input_ids'])+10\n",
    "        sm_prob = compute_token_probs_api(token_label, prompt, sm_prob_gen, max_tokens)\n",
    "        value[data_key][token_label]['shadow_models'].append(float(sm_prob))\n",
    "\n",
    "\n",
    "def add_model_probs(results, client, world_model_endpoints, shadow_model_endpoints, model_type='world'):\n",
    "    for t_id, value in tqdm(results.items(), desc=\"processing results\"):\n",
    "        print(f\"processing {t_id}\")\n",
    "        y_stars_order = list(value['y_stars'].keys())\n",
    "        y_non_stars_order = list(value['y_NON_stars'].keys())\n",
    "\n",
    "        # y_stars \n",
    "        for y_star in tqdm(y_stars_order, leave=True, desc=\"processing y_stars\"):\n",
    "            prompt = value['y_stars'][y_star]['prompt']\n",
    "            if model_type == 'world':\n",
    "                add_world_model_probs_single(value, y_star, prompt, client, world_model_endpoints, is_star=True)\n",
    "            else:\n",
    "                add_shadow_model_probs_single(value, y_star, prompt, client, shadow_model_endpoints, is_star=True)\n",
    "\n",
    "        # y_non_stars \n",
    "        for y_non_star in tqdm(y_non_stars_order, leave=True, desc=\"processing y_non_stars\"):\n",
    "            prompt = value['y_NON_stars'][y_non_star]['prompt']\n",
    "            if model_type == 'world':\n",
    "                add_world_model_probs_single(value, y_non_star, prompt, client, world_model_endpoints, is_star=False)\n",
    "            else:\n",
    "                add_shadow_model_probs_single(value, y_non_star, prompt, client, shadow_model_endpoints, is_star=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8e2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "id=3\n",
    "with open('model_map.json') as f:\n",
    "    model_map=json.load(f)\n",
    "with open(f'target_token_probs_train_{id}_10_epochs_with_prompt_higher.json', 'r') as f:\n",
    "    all_model_probs = json.load(f)    \n",
    "key = '779d92de61a5035835e5023ca79e2e5b6124c6300c3ceb0e07e374f948554116'\n",
    "client = Together(api_key=key)\n",
    "shadow_model_endpoints=[model_map[f'shadow_train_{id}']['api_key']]\n",
    "world_model_endpoints = [\n",
    "    \"google/gemma-2b-it\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae104095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "processing results:   0%|                               | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:03<00:21,  3.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:05<00:11,  2.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:06<00:07,  1.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:08<00:05,  1.83s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:09<00:03,  1.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:11<00:01,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:12<00:00,  1.81s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:08,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:02<00:07,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:05,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:05<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:06<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:08<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:09<00:00,  1.41s/it]\u001b[A\n",
      "processing results:   1%|▏                      | 1/100 [00:22<37:10, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:06,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.56s/it]\u001b[A\n",
      "processing results:   2%|▍                      | 2/100 [00:40<32:23, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.37s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "processing results:   3%|▋                      | 3/100 [00:54<27:46, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:03,  1.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:03<00:02,  1.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.36s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.38s/it]\u001b[A\n",
      "processing results:   4%|▉                      | 4/100 [01:06<24:25, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.37s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:03,  1.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:03<00:02,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.37s/it]\u001b[A\n",
      "processing results:   5%|█▏                     | 5/100 [01:20<23:16, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:03<00:02,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.35s/it]\u001b[A\n",
      "processing results:   6%|█▍                     | 6/100 [01:34<22:36, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:12,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:10,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:08<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:11<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:10,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:03<00:09,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:06<00:06,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:09<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.50s/it]\u001b[A\n",
      "processing results:   7%|█▌                     | 7/100 [01:59<27:46, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.44s/it]\u001b[A\n",
      "processing results:   8%|█▊                     | 8/100 [02:13<25:38, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:08,  1.16s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:02<00:08,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:03<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:05<00:05,  1.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:06<00:04,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:08<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:09<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:11<00:00,  1.40s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:10,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:02<00:08,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:05<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:08<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.44s/it]\u001b[A\n",
      "processing results:   9%|██                     | 9/100 [02:36<28:11, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:11,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:10,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:05<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:08<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:11<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:12,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:03<00:10,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:08,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:05<00:07,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:07<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:08<00:04,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:10<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:11<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:13<00:00,  1.53s/it]\u001b[A\n",
      "processing results:  10%|██▏                   | 10/100 [03:03<31:50, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.38s/it]\u001b[A\n",
      "processing results:  11%|██▍                   | 11/100 [03:16<27:34, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.40s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.45s/it]\u001b[A\n",
      "processing results:  12%|██▋                   | 12/100 [03:30<25:19, 17.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/13 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|█▊                      | 1/13 [00:01<00:19,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 2/13 [00:03<00:17,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  23%|█████▌                  | 3/13 [00:04<00:15,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  31%|███████▍                | 4/13 [00:06<00:13,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▏              | 5/13 [00:07<00:12,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  46%|███████████             | 6/13 [00:09<00:10,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  54%|████████████▉           | 7/13 [00:10<00:08,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|██████████████▊         | 8/13 [00:12<00:07,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  69%|████████████████▌       | 9/13 [00:14<00:06,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  77%|█████████████████▋     | 10/13 [00:15<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▍   | 11/13 [00:17<00:03,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████▏ | 12/13 [00:18<00:01,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 13/13 [00:20<00:00,  1.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:01<00:15,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:02<00:13,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:04<00:11,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:05<00:10,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:07<00:09,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:09<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:10<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:11<00:04,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:13<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:15<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:16<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  13%|██▊                   | 13/100 [04:07<33:41, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\n",
      "processing results:  14%|███                   | 14/100 [04:21<29:29, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:03,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.43s/it]\u001b[A\n",
      "processing results:  15%|███▎                  | 15/100 [04:34<25:47, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:09,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:03<00:07,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:09<00:01,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  16%|███▌                  | 16/100 [04:53<25:52, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:05,  1.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:07,  1.84s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:05,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:05<00:03,  1.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.56s/it]\u001b[A\n",
      "processing results:  17%|███▋                  | 17/100 [05:10<24:47, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:04,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.41s/it]\u001b[A\n",
      "processing results:  18%|███▉                  | 18/100 [05:24<23:07, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:04,  1.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:03,  1.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  19%|████▏                 | 19/100 [05:39<21:55, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:07,  1.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:02<00:07,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:03<00:06,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:05<00:05,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:06<00:03,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:08<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:09<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:11<00:00,  1.40s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:03,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:06<00:01,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.36s/it]\u001b[A\n",
      "processing results:  20%|████▍                 | 20/100 [05:58<22:54, 17.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:05,  1.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.42s/it]\u001b[A\n",
      "processing results:  21%|████▌                 | 21/100 [06:16<22:44, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.40s/it]\u001b[A\n",
      "processing results:  22%|████▊                 | 22/100 [06:29<20:42, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:09,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      "processing results:  23%|█████                 | 23/100 [06:48<21:37, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:08,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:07,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:09,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:03<00:07,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:06<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:07<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:09<00:01,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:10<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  24%|█████▎                | 24/100 [07:08<22:47, 17.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:05,  1.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:06<00:01,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.38s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.52s/it]\u001b[A\n",
      "processing results:  25%|█████▌                | 25/100 [07:26<22:15, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:10,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:02<00:09,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:08,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:05<00:06,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:08<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:11<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.49s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:10,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:02<00:08,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:05<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:08<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.45s/it]\u001b[A\n",
      "processing results:  26%|█████▋                | 26/100 [07:51<24:37, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:11,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:10,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:05<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:12<00:01,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.49s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:09,  1.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:02<00:08,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:05<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:08<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  27%|█████▉                | 27/100 [08:16<26:14, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:03,  1.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:03<00:02,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.33s/it]\u001b[A\n",
      "processing results:  28%|██████▏               | 28/100 [08:30<23:06, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:06<00:01,  1.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:07<00:00,  1.30s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:03<00:03,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:06<00:01,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:07<00:00,  1.27s/it]\u001b[A\n",
      "processing results:  29%|██████▍               | 29/100 [08:45<21:26, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.62s/it]\u001b[A\n",
      "processing results:  30%|██████▌               | 30/100 [09:04<21:26, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "processing results:  31%|██████▊               | 31/100 [09:19<19:48, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:06<00:01,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:06<00:01,  1.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.35s/it]\u001b[A\n",
      "processing results:  32%|███████               | 32/100 [09:35<19:18, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  33%|███████▎              | 33/100 [09:50<18:16, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:04,  1.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:03,  1.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:03<00:02,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.34s/it]\u001b[A\n",
      "processing results:  34%|███████▍              | 34/100 [10:04<17:13, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:01<00:14,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:03<00:13,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:04<00:11,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:06<00:10,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:08<00:07,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:09<00:06,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:11<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:12<00:03,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:14<00:01,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:15<00:00,  1.60s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:16,  1.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:03<00:13,  1.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:05<00:11,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:06<00:10,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:08<00:08,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:10<00:06,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:11<00:05,  1.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:13<00:03,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:14<00:01,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:16<00:00,  1.64s/it]\u001b[A\n",
      "processing results:  35%|███████▋              | 35/100 [10:37<22:23, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:12,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:11,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:07,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:06,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:11<00:03,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:12<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:14<00:00,  1.56s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:11,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:02<00:10,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:08,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:05<00:06,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:07<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:08<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:09<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:11<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:12<00:00,  1.42s/it]\u001b[A\n",
      "processing results:  36%|███████▉              | 36/100 [11:03<24:01, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/3 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 1/3 [00:01<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 2/3 [00:02<00:01,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 3/3 [00:04<00:00,  1.37s/it]\u001b[A\n",
      "processing results:  37%|████████▏             | 37/100 [11:15<20:05, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:06<00:01,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.36s/it]\u001b[A\n",
      "processing results:  38%|████████▎             | 38/100 [11:32<19:06, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.42s/it]\u001b[A\n",
      "processing results:  39%|████████▌             | 39/100 [11:44<17:03, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:11,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:02<00:10,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:08,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:05<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:06<00:05,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:08<00:03,  1.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:09<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:11<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:12<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:08,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:02<00:08,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:05<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:08<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.47s/it]\u001b[A\n",
      "processing results:  40%|████████▊             | 40/100 [12:09<19:06, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:13,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:10,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:08,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:07,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:06,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:12<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:10,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:02<00:10,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:09,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:06<00:08,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:08<00:06,  1.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:09<00:04,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:11<00:03,  1.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:13<00:01,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:14<00:00,  1.62s/it]\u001b[A\n",
      "processing results:  41%|█████████             | 41/100 [12:38<21:35, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:08,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:06,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:08,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:02<00:06,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:05<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:07<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:08<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:10<00:00,  1.45s/it]\u001b[A\n",
      "processing results:  42%|█████████▏            | 42/100 [12:58<20:50, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:07,  1.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:06,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:02,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:09,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:03<00:08,  1.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:05<00:04,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:07<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:08<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:10<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  43%|█████████▍            | 43/100 [13:19<20:14, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:06<00:01,  1.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.38s/it]\u001b[A\n",
      "processing results:  44%|█████████▋            | 44/100 [13:35<18:29, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:11,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:03<00:09,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:04<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:06<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:07<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:08<00:02,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:10<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:11<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      "processing results:  45%|█████████▉            | 45/100 [13:56<18:21, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\n",
      "processing results:  46%|██████████            | 46/100 [14:11<16:39, 18.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:08,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:06,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:03<00:05,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:03,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:06<00:02,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:09<00:00,  1.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.36s/it]\u001b[A\n",
      "processing results:  47%|██████████▎           | 47/100 [14:27<15:43, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:08,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:07,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:06<00:02,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:09<00:00,  1.33s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:08,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:02<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:03<00:05,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:05<00:04,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:06<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:08<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:09<00:00,  1.38s/it]\u001b[A\n",
      "processing results:  48%|██████████▌           | 48/100 [14:46<15:45, 18.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:06<00:00,  1.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "processing results:  49%|██████████▊           | 49/100 [15:00<14:24, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:10,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:02<00:08,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:04<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:06<00:06,  1.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:07<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:09<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:10<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:12<00:00,  1.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:12,  1.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:03<00:08,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:06<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:09<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:12<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  50%|███████████           | 50/100 [15:24<15:56, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:01<00:15,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:02<00:12,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:04<00:12,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:06<00:10,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:07<00:08,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:08<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:10<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:11<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:13<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:14<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:16<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:13,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:03<00:12,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:04<00:10,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:06<00:08,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:07<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:08<00:05,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:10<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:11<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:13<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:14<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  51%|███████████▏          | 51/100 [15:55<18:32, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:01<00:14,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:03<00:12,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:04<00:11,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:06<00:09,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:07<00:07,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:09<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:10<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:12<00:02,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:13<00:01,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:15<00:00,  1.54s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:12,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:02<00:11,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:04<00:10,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:05<00:08,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:07<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:08<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:10<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:11<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:13<00:01,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:15<00:00,  1.53s/it]\u001b[A\n",
      "processing results:  52%|███████████▍          | 52/100 [16:26<20:04, 25.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:04,  1.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:03,  1.16s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:03<00:02,  1.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.31s/it]\u001b[A\n",
      "processing results:  53%|███████████▋          | 53/100 [16:40<16:59, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:01<00:14,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:03<00:12,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:04<00:11,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:06<00:09,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:07<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:08<00:05,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:10<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:11<00:02,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:13<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:14<00:00,  1.49s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:13,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:03<00:13,  1.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:05<00:14,  2.06s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:07<00:11,  1.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:09<00:08,  1.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:10<00:06,  1.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:12<00:05,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:14<00:03,  1.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:15<00:01,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:17<00:00,  1.71s/it]\u001b[A\n",
      "processing results:  54%|███████████▉          | 54/100 [17:12<19:00, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.52s/it]\u001b[A\n",
      "processing results:  55%|████████████          | 55/100 [17:30<17:05, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.54s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.44s/it]\u001b[A\n",
      "processing results:  56%|████████████▎         | 56/100 [17:48<15:38, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:12,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:10,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:03,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:12<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:13,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:03<00:10,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:10,  1.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:06<00:08,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:08<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:09<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:11<00:03,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:12<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:13<00:00,  1.55s/it]\u001b[A\n",
      "processing results:  57%|████████████▌         | 57/100 [18:15<16:38, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  58%|████████████▊         | 58/100 [18:33<15:05, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:09,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:03<00:07,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:06,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:06<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:09<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:08,  1.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:08<00:01,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.61s/it]\u001b[A\n",
      "processing results:  59%|████████████▉         | 59/100 [18:53<14:25, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  60%|█████████████▏        | 60/100 [19:11<13:30, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:08,  1.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:07<00:04,  2.11s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:09<00:01,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:10<00:00,  1.77s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:08,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.56s/it]\u001b[A\n",
      "processing results:  61%|█████████████▍        | 61/100 [19:31<13:07, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:03<00:04,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  62%|█████████████▋        | 62/100 [19:47<11:58, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:01<00:15,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:03<00:14,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:04<00:11,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:05<00:09,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:07<00:08,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:08<00:07,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:10<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:11<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:13<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:15<00:01,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:17<00:00,  1.56s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:12,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:02<00:10,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:09,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:06<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:07<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:09<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:10<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:12<00:01,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:13<00:00,  1.53s/it]\u001b[A\n",
      "processing results:  63%|█████████████▊        | 63/100 [20:18<13:52, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:08,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      "processing results:  64%|██████████████        | 64/100 [20:36<12:40, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:01<00:13,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:02<00:12,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:04<00:11,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:06<00:11,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:07<00:09,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:09<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:10<00:06,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:12<00:04,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:14<00:03,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:15<00:01,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:17<00:00,  1.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:11,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:02<00:09,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:09,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:05<00:07,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:07<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:08<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:10<00:03,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:12<00:01,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:14<00:00,  1.60s/it]\u001b[A\n",
      "processing results:  65%|██████████████▎       | 65/100 [21:08<14:10, 24.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:08,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "processing results:  66%|██████████████▌       | 66/100 [21:26<12:45, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:06,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.54s/it]\u001b[A\n",
      "processing results:  67%|██████████████▋       | 67/100 [21:43<11:21, 20.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.45s/it]\u001b[A\n",
      "processing results:  68%|██████████████▉       | 68/100 [21:58<10:07, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.43s/it]\u001b[A\n",
      "processing results:  69%|███████████████▏      | 69/100 [22:12<09:06, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:13,  1.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:03<00:11,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:08<00:06,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:11<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:12<00:01,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:14<00:00,  1.59s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:11,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:03<00:09,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:06<00:06,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:09<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:10<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:12<00:00,  1.55s/it]\u001b[A\n",
      "processing results:  70%|███████████████▍      | 70/100 [22:39<10:10, 20.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  71%|███████████████▌      | 71/100 [22:56<09:23, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "processing results:  72%|███████████████▊      | 72/100 [23:14<08:49, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.52s/it]\u001b[A\n",
      "processing results:  73%|████████████████      | 73/100 [23:28<07:55, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:10,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:03<00:09,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:04<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:05<00:05,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:07<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:09<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:10<00:01,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:12<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:10,  1.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:03<00:08,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:06,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:06<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:07<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:09<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:10<00:00,  1.53s/it]\u001b[A\n",
      "processing results:  74%|████████████████▎     | 74/100 [23:51<08:18, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:01<00:17,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:03<00:15,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:04<00:13,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:06<00:12,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:07<00:10,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:08<00:08,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:10<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:11<00:05,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:12<00:04,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:14<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:15<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:18<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:13,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:02<00:11,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:04<00:09,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:05<00:08,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:06<00:06,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:08<00:05,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:09<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:11<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:13<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:14<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  75%|████████████████▌     | 75/100 [24:24<09:41, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.56s/it]\u001b[A\n",
      "processing results:  76%|████████████████▋     | 76/100 [24:39<08:17, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/33 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   3%|▋                       | 1/33 [00:02<01:08,  2.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   6%|█▍                      | 2/33 [00:03<00:55,  1.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 3/33 [00:05<00:58,  1.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|██▉                     | 4/33 [00:07<00:57,  1.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 5/33 [00:09<00:49,  1.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 6/33 [00:11<00:51,  1.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  21%|█████                   | 7/33 [00:13<00:49,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  24%|█████▊                  | 8/33 [00:15<00:51,  2.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 9/33 [00:17<00:47,  1.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|██████▉                | 10/33 [00:19<00:44,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|███████▋               | 11/33 [00:21<00:42,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▎              | 12/33 [00:23<00:42,  2.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  39%|█████████              | 13/33 [00:25<00:41,  2.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|█████████▊             | 14/33 [00:27<00:39,  2.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▍            | 15/33 [00:29<00:37,  2.07s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  48%|███████████▏           | 16/33 [00:31<00:31,  1.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  52%|███████████▊           | 17/33 [00:33<00:30,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|████████████▌          | 18/33 [00:35<00:29,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|█████████████▏         | 19/33 [00:36<00:24,  1.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  61%|█████████████▉         | 20/33 [00:38<00:23,  1.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|██████████████▋        | 21/33 [00:40<00:22,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|███████████████▎       | 22/33 [00:42<00:21,  1.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████       | 23/33 [00:44<00:19,  1.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|████████████████▋      | 24/33 [00:46<00:17,  1.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  76%|█████████████████▍     | 25/33 [00:48<00:16,  2.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  79%|██████████████████     | 26/33 [00:50<00:14,  2.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|██████████████████▊    | 27/33 [00:52<00:11,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▌   | 28/33 [00:54<00:09,  1.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|████████████████████▏  | 29/33 [00:56<00:08,  2.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 30/33 [00:58<00:05,  1.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  94%|█████████████████████▌ | 31/33 [01:00<00:04,  2.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  97%|██████████████████████▎| 32/33 [01:02<00:01,  1.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 33/33 [01:04<00:00,  1.95s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/29 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   3%|▋                   | 1/29 [00:01<00:49,  1.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   7%|█▍                  | 2/29 [00:03<00:52,  1.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 3/29 [00:05<00:50,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|██▊                 | 4/29 [00:08<00:52,  2.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▍                | 5/29 [00:10<00:50,  2.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  21%|████▏               | 6/29 [00:12<00:48,  2.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  24%|████▊               | 7/29 [00:14<00:46,  2.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  28%|█████▌              | 8/29 [00:16<00:44,  2.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  31%|██████▏             | 9/29 [00:18<00:40,  2.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  34%|██████▌            | 10/29 [00:20<00:36,  1.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▏           | 11/29 [00:22<00:34,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  41%|███████▊           | 12/29 [00:23<00:30,  1.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|████████▌          | 13/29 [00:25<00:30,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  48%|█████████▏         | 14/29 [00:27<00:29,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  52%|█████████▊         | 15/29 [00:29<00:26,  1.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▍        | 16/29 [00:31<00:25,  1.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  59%|███████████▏       | 17/29 [00:33<00:21,  1.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|███████████▊       | 18/29 [00:35<00:20,  1.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  66%|████████████▍      | 19/29 [00:37<00:19,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  69%|█████████████      | 20/29 [00:39<00:17,  1.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  72%|█████████████▊     | 21/29 [00:41<00:16,  2.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  76%|██████████████▍    | 22/29 [00:43<00:14,  2.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  79%|███████████████    | 23/29 [00:45<00:12,  2.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|███████████████▋   | 24/29 [00:47<00:10,  2.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|████████████████▍  | 25/29 [00:48<00:07,  1.83s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|█████████████████  | 26/29 [00:50<00:05,  1.84s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  93%|█████████████████▋ | 27/29 [00:52<00:03,  1.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  97%|██████████████████▎| 28/29 [00:54<00:01,  1.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 29/29 [00:56<00:00,  1.95s/it]\u001b[A\n",
      "processing results:  77%|████████████████▉     | 77/100 [26:40<19:29, 50.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:06,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.45s/it]\u001b[A\n",
      "processing results:  78%|█████████████████▏    | 78/100 [26:57<14:57, 40.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:03<00:03,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:05<00:01,  1.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:06<00:00,  1.67s/it]\u001b[A\n",
      "processing results:  79%|█████████████████▍    | 79/100 [27:11<11:27, 32.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:01<00:15,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:02<00:14,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:04<00:14,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:05<00:11,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:07<00:10,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:08<00:09,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:10<00:07,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:12<00:06,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:13<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:15<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:16<00:01,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:18<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   8%|█▋                  | 1/12 [00:01<00:16,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▎                | 2/12 [00:02<00:13,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████               | 3/12 [00:04<00:12,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|██████▋             | 4/12 [00:05<00:11,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  42%|████████▎           | 5/12 [00:07<00:09,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 6/12 [00:08<00:09,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  58%|███████████▋        | 7/12 [00:10<00:07,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|█████████████▎      | 8/12 [00:12<00:06,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████     | 9/12 [00:13<00:04,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|███████████████▊   | 10/12 [00:15<00:03,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  92%|█████████████████▍ | 11/12 [00:16<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 12/12 [00:18<00:00,  1.54s/it]\u001b[A\n",
      "processing results:  80%|█████████████████▌    | 80/100 [27:48<11:18, 33.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.52s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:06,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "processing results:  81%|█████████████████▊    | 81/100 [28:06<09:14, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.44s/it]\u001b[A\n",
      "processing results:  82%|██████████████████    | 82/100 [28:20<07:25, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.40s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:02<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.38s/it]\u001b[A\n",
      "processing results:  83%|██████████████████▎   | 83/100 [28:33<05:58, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.54s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  84%|██████████████████▍   | 84/100 [28:48<05:08, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:01<00:11,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:02<00:10,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:04<00:09,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:06<00:07,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:07<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:09<00:04,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:10<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:11<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:13<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:10,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:02<00:08,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:04<00:07,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:05<00:06,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:07<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:08<00:02,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:09<00:01,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:11<00:00,  1.39s/it]\u001b[A\n",
      "processing results:  85%|██████████████████▋   | 85/100 [29:13<05:13, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/13 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|█▊                      | 1/13 [00:01<00:19,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 2/13 [00:03<00:17,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  23%|█████▌                  | 3/13 [00:04<00:15,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  31%|███████▍                | 4/13 [00:06<00:14,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▏              | 5/13 [00:08<00:13,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  46%|███████████             | 6/13 [00:09<00:10,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  54%|████████████▉           | 7/13 [00:10<00:09,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|██████████████▊         | 8/13 [00:12<00:07,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  69%|████████████████▌       | 9/13 [00:14<00:06,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  77%|█████████████████▋     | 10/13 [00:15<00:04,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▍   | 11/13 [00:17<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████▏ | 12/13 [00:18<00:01,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 13/13 [00:20<00:00,  1.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:01<00:14,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:03<00:14,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:04<00:12,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:06<00:11,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:07<00:09,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:09<00:08,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:11<00:06,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:12<00:04,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:14<00:03,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:16<00:01,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:17<00:00,  1.60s/it]\u001b[A\n",
      "processing results:  86%|██████████████████▉   | 86/100 [29:51<06:03, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:01<00:13,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:02<00:12,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:04<00:11,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:05<00:10,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:07<00:08,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:08<00:07,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:10<00:06,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:12<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:13<00:03,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:14<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:16<00:00,  1.50s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:01<00:10,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:03<00:11,  1.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:05<00:08,  1.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:06<00:06,  1.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:08<00:04,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:09<00:03,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:11<00:01,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:12<00:00,  1.59s/it]\u001b[A\n",
      "processing results:  87%|███████████████████▏  | 87/100 [30:20<05:50, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:02<00:05,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:05<00:02,  1.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:08<00:00,  1.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:02<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:06<00:03,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:09<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  88%|███████████████████▎  | 88/100 [30:38<04:50, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:01<00:11,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:03<00:09,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:04<00:07,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:06<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:07<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:08<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:10<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:11<00:00,  1.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:08,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:02<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:05,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:05<00:04,  1.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:06<00:02,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:08<00:01,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:09<00:00,  1.33s/it]\u001b[A\n",
      "processing results:  89%|███████████████████▌  | 89/100 [30:59<04:15, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:08,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:03<00:07,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:04<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:02,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:04,  1.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.41s/it]\u001b[A\n",
      "processing results:  90%|███████████████████▊  | 90/100 [31:16<03:34, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.52s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:06,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  91%|████████████████████  | 91/100 [31:31<02:55, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:01<00:14,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:03<00:12,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:04<00:10,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:05<00:08,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:07<00:07,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:08<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:10<00:04,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:11<00:02,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:13<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:14<00:00,  1.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:01<00:12,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:03<00:11,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:04<00:09,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:06<00:07,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:07<00:06,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:09<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:10<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:12<00:01,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:13<00:00,  1.50s/it]\u001b[A\n",
      "processing results:  92%|████████████████████▏ | 92/100 [31:59<02:57, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:01<00:04,  1.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:03<00:03,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:04<00:01,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:05<00:00,  1.49s/it]\u001b[A\n",
      "processing results:  93%|████████████████████▍ | 93/100 [32:14<02:20, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:01<00:07,  1.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:02<00:06,  1.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:03<00:05,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:05<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:07<00:03,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:08<00:01,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:10<00:00,  1.49s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:01<00:08,  1.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:02<00:07,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:04<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:06<00:04,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:07<00:02,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:09<00:01,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:10<00:00,  1.51s/it]\u001b[A\n",
      "processing results:  94%|████████████████████▋ | 94/100 [32:36<02:02, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:01<00:14,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:03<00:13,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:04<00:12,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:05<00:10,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:07<00:08,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:08<00:07,  1.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:10<00:05,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:11<00:04,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:13<00:02,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:14<00:01,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:16<00:00,  1.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:01<00:12,  1.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:03<00:14,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:04<00:12,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:06<00:11,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:07<00:09,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:09<00:08,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:10<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:12<00:04,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:14<00:03,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:15<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:17<00:00,  1.57s/it]\u001b[A\n",
      "processing results:  95%|████████████████████▉ | 95/100 [33:09<02:01, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:02<00:10,  2.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:05<00:04,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.57s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:01<00:07,  1.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:03<00:06,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:04<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:05<00:02,  1.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      "processing results:  96%|█████████████████████ | 96/100 [33:27<01:29, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:06,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:03<00:04,  1.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:03,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:06<00:01,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.60s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.48s/it]\u001b[A\n",
      "processing results:  97%|█████████████████████▎| 97/100 [33:43<01:01, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:01<00:17,  1.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:03<00:16,  1.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:04<00:14,  1.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:06<00:11,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:07<00:11,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:09<00:09,  1.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:11<00:08,  1.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:12<00:06,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:14<00:04,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:16<00:03,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:17<00:01,  1.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:19<00:00,  1.61s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:01<00:13,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:02<00:11,  1.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:04<00:10,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:06<00:09,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:07<00:07,  1.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:09<00:06,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:10<00:04,  1.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:12<00:03,  1.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:14<00:01,  1.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:15<00:00,  1.60s/it]\u001b[A\n",
      "processing results:  98%|█████████████████████▌| 98/100 [34:18<00:49, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:01<00:05,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:02<00:04,  1.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:04<00:02,  1.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:05<00:01,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:02<00:04,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:03,  1.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:06<00:01,  1.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:07<00:00,  1.54s/it]\u001b[A\n",
      "processing results:  99%|█████████████████████▊| 99/100 [34:33<00:21, 21.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:01<00:07,  1.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:03<00:06,  1.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:04<00:04,  1.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:06<00:03,  1.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:07<00:01,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:09<00:00,  1.51s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:01<00:05,  1.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:03<00:04,  1.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:04<00:02,  1.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:05<00:01,  1.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:06<00:00,  1.35s/it]\u001b[A\n",
      "processing results: 100%|█████████████████████| 100/100 [34:49<00:00, 20.89s/it]\n"
     ]
    }
   ],
   "source": [
    "add_model_probs(all_model_probs, client, [], shadow_model_endpoints, model_type='shadow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e62d587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "processing results:   0%|                               | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:05<00:34,  5.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:10<00:26,  5.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:15<00:19,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:19<00:14,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:28<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.68s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:25,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:08<00:21,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:13<00:17,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:23<00:09,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:28<00:04,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:32<00:00,  4.71s/it]\u001b[A\n",
      "processing results:   1%|▏                    | 1/100 [01:05<1:48:22, 65.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:23,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:09,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:23<00:04,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.65s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:22,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.35s/it]\u001b[A\n",
      "processing results:   2%|▍                    | 2/100 [01:59<1:36:04, 58.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:03<00:15,  3.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.16s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.20s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:20<00:00,  4.15s/it]\u001b[A\n",
      "processing results:   3%|▋                    | 3/100 [02:42<1:23:00, 51.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:14,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:09<00:09,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:14<00:04,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:18<00:00,  4.65s/it]\u001b[A\n",
      "processing results:   4%|▊                    | 4/100 [03:23<1:15:47, 47.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.20s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.26s/it]\u001b[A\n",
      "processing results:   5%|█                    | 5/100 [04:06<1:12:30, 45.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.26s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.11s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.12s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:20<00:00,  4.17s/it]\u001b[A\n",
      "processing results:   6%|█▎                   | 6/100 [04:48<1:09:48, 44.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:35,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:26,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:22,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:22<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:26<00:13,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:30<00:08,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:35<00:04,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:40<00:00,  4.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:32,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:27,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:23,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:19<00:19,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:23<00:14,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:28<00:09,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:37<00:00,  4.73s/it]\u001b[A\n",
      "processing results:   7%|█▍                   | 7/100 [06:06<1:25:57, 55.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.06s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:20<00:00,  4.16s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.27s/it]\u001b[A\n",
      "processing results:   8%|█▋                   | 8/100 [06:48<1:18:32, 51.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:32,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:08<00:26,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:13<00:22,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:17<00:17,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:22<00:13,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:26<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:31<00:04,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:35<00:00,  4.49s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:33,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:28,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:13<00:22,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:18<00:17,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:22<00:13,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:26<00:08,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:30<00:04,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:35<00:00,  4.41s/it]\u001b[A\n",
      "processing results:   9%|█▉                   | 9/100 [07:59<1:27:11, 57.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:37,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:27,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:22,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:22<00:17,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:26<00:12,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:31<00:08,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:35<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:40<00:00,  4.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:35,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:08<00:29,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:26,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:17<00:22,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:21<00:17,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:26<00:13,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:31<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:35<00:04,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:39<00:00,  4.40s/it]\u001b[A\n",
      "processing results:  10%|██                  | 10/100 [09:19<1:36:38, 64.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:19,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:12,  4.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:08<00:08,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:13<00:04,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:17<00:00,  4.38s/it]\u001b[A\n",
      "processing results:  11%|██▏                 | 11/100 [09:59<1:24:08, 56.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.28s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n",
      "processing results:  12%|██▍                 | 12/100 [10:42<1:17:06, 52.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/13 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|█▊                      | 1/13 [00:04<00:57,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 2/13 [00:09<00:52,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  23%|█████▌                  | 3/13 [00:14<00:49,  4.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  31%|███████▍                | 4/13 [00:20<00:48,  5.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▏              | 5/13 [00:25<00:40,  5.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  46%|███████████             | 6/13 [00:30<00:34,  4.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  54%|████████████▉           | 7/13 [00:35<00:29,  4.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|██████████████▊         | 8/13 [00:39<00:24,  4.84s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  69%|████████████████▌       | 9/13 [00:44<00:19,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  77%|█████████████████▋     | 10/13 [00:49<00:14,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▍   | 11/13 [00:53<00:09,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████▏ | 12/13 [00:58<00:04,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 13/13 [01:03<00:00,  4.86s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:04<00:49,  4.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:09<00:44,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:14<00:39,  4.97s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:20<00:35,  5.11s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:25<00:30,  5.03s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:29<00:24,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:34<00:19,  4.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:39<00:14,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:44<00:09,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:49<00:05,  5.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:54<00:00,  4.96s/it]\u001b[A\n",
      "processing results:  13%|██▌                 | 13/100 [12:39<1:44:49, 72.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:20<00:00,  4.18s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.21s/it]\u001b[A\n",
      "processing results:  14%|██▊                 | 14/100 [13:21<1:30:29, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.03s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.36s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:14,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:09<00:08,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:13<00:04,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:18<00:00,  4.66s/it]\u001b[A\n",
      "processing results:  15%|███                 | 15/100 [14:02<1:19:45, 56.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:29,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:24,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:14<00:18,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:13,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:28<00:04,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:33<00:00,  4.72s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:12,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.46s/it]\u001b[A\n",
      "processing results:  16%|███▏                | 16/100 [15:02<1:20:17, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:05<00:25,  5.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:14<00:14,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:19<00:09,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:24<00:04,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:28<00:00,  4.76s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:18<00:04,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.42s/it]\u001b[A\n",
      "processing results:  17%|███▍                | 17/100 [15:52<1:16:33, 55.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:23<00:00,  4.69s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:14,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:16<00:11,  5.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:20<00:05,  5.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:25<00:00,  5.08s/it]\u001b[A\n",
      "processing results:  18%|███▌                | 18/100 [16:41<1:12:58, 53.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:18,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:13,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.47s/it]\u001b[A\n",
      "processing results:  19%|███▊                | 19/100 [17:26<1:08:29, 50.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:32,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:08<00:26,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:13<00:22,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:18<00:18,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:22<00:13,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:27<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:31<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:36<00:00,  4.61s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:05<00:25,  5.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:18,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:14<00:14,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:23<00:04,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.66s/it]\u001b[A\n",
      "processing results:  20%|████                | 20/100 [18:30<1:13:17, 54.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:16<00:08,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:25<00:00,  4.30s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:25<00:00,  4.32s/it]\u001b[A\n",
      "processing results:  21%|████▏               | 21/100 [19:22<1:11:05, 53.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:18,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:14,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:09,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:23<00:00,  4.66s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:13,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:09<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:13<00:04,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:17<00:00,  4.49s/it]\u001b[A\n",
      "processing results:  22%|████▍               | 22/100 [20:03<1:05:13, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:27,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:22,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:22<00:08,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:26<00:04,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:31<00:00,  4.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:22,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.47s/it]\u001b[A\n",
      "processing results:  23%|████▌               | 23/100 [21:01<1:07:20, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:05<00:31,  5.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:10<00:24,  4.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:14<00:18,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:27<00:04,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.60s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:27,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:09<00:24,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:14<00:19,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:14,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:23<00:09,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:27<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:32<00:00,  4.64s/it]\u001b[A\n",
      "processing results:  24%|████▊               | 24/100 [22:06<1:11:07, 56.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.47s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:22,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.39s/it]\u001b[A\n",
      "processing results:  25%|█████               | 25/100 [22:59<1:09:03, 55.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:36,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:27,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:23<00:18,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:28<00:14,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:32<00:09,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:37<00:04,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:42<00:00,  4.71s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:34,  4.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:29,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:24,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:18<00:18,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:23<00:13,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:28<00:09,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:33<00:04,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:37<00:00,  4.72s/it]\u001b[A\n",
      "processing results:  26%|█████▏              | 26/100 [24:19<1:17:21, 62.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:37,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:27,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:22,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:22<00:18,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:27<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:32<00:09,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:36<00:04,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:41<00:00,  4.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:34,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:24,  4.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:19<00:19,  4.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:24<00:14,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:28<00:09,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:33<00:04,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:39<00:00,  4.88s/it]\u001b[A\n",
      "processing results:  27%|█████▍              | 27/100 [25:40<1:22:43, 67.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.18s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.27s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.49s/it]\u001b[A\n",
      "processing results:  28%|█████▌              | 28/100 [26:23<1:12:53, 60.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:23,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:14<00:14,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:08,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.56s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:05<00:25,  5.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:19,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:14<00:15,  5.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:20<00:10,  5.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:25<00:05,  5.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:29<00:00,  4.97s/it]\u001b[A\n",
      "processing results:  29%|█████▊              | 29/100 [27:21<1:10:36, 59.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:09,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:23<00:04,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.62s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.47s/it]\u001b[A\n",
      "processing results:  30%|██████              | 30/100 [28:15<1:07:49, 58.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:09,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:05<00:21,  5.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:14,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:18<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.51s/it]\u001b[A\n",
      "processing results:  31%|██████▏             | 31/100 [29:00<1:02:22, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:03<00:19,  3.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:25<00:00,  4.32s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.44s/it]\u001b[A\n",
      "processing results:  32%|██████▍             | 32/100 [29:53<1:00:54, 53.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:14<00:09,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:19<00:05,  5.03s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:23<00:00,  4.77s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.42s/it]\u001b[A\n",
      "processing results:  33%|███████▎              | 33/100 [30:39<57:24, 51.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:09,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.43s/it]\u001b[A\n",
      "processing results:  34%|███████▍              | 34/100 [31:23<54:10, 49.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:04<00:40,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:09<00:36,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:14<00:33,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:18<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:23<00:23,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:28<00:19,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:33<00:14,  4.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:38<00:09,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:43<00:04,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:47<00:00,  4.76s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:43,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:09<00:38,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:14<00:32,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:18<00:28,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:23<00:23,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:28<00:18,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:32<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:37<00:09,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:42<00:04,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:46<00:00,  4.69s/it]\u001b[A\n",
      "processing results:  35%|███████             | 35/100 [32:58<1:08:04, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:35,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:08<00:30,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:27,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:17<00:22,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:22<00:17,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:27<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:31<00:09,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:36<00:04,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:40<00:00,  4.52s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:36,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:09<00:32,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:28,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:18<00:23,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:23<00:18,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:28<00:14,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:32<00:09,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:37<00:04,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:41<00:00,  4.65s/it]\u001b[A\n",
      "processing results:  36%|███████▏            | 36/100 [34:20<1:13:19, 68.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.20s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/3 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 1/3 [00:04<00:08,  4.18s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 2/3 [00:08<00:04,  4.13s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 3/3 [00:12<00:00,  4.32s/it]\u001b[A\n",
      "processing results:  37%|███████▍            | 37/100 [34:55<1:01:22, 58.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.35s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:20,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.41s/it]\u001b[A\n",
      "processing results:  38%|████████▎             | 38/100 [35:47<58:34, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.34s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:14,  4.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:09<00:09,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:13<00:04,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:18<00:00,  4.64s/it]\u001b[A\n",
      "processing results:  39%|████████▌             | 39/100 [36:27<52:37, 51.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:36,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:14<00:28,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:23,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:23<00:18,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:28<00:14,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:32<00:09,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:37<00:04,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:41<00:00,  4.62s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:05<00:35,  5.03s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:13<00:22,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:18<00:18,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:22<00:13,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:27<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:36<00:00,  4.60s/it]\u001b[A\n",
      "processing results:  40%|████████▊             | 40/100 [37:46<59:44, 59.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:39,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:33,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:14<00:28,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:19<00:24,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:24<00:19,  4.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:29<00:15,  5.07s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:34<00:09,  5.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:39<00:04,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:44<00:00,  4.91s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:33,  4.13s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:09<00:32,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:27,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:17<00:22,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:22<00:17,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:26<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:31<00:09,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:36<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:41<00:00,  4.59s/it]\u001b[A\n",
      "processing results:  41%|████████▏           | 41/100 [39:11<1:06:20, 67.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:28,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:24,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:14<00:19,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:19<00:14,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:28<00:04,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.67s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:09<00:22,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:14<00:18,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:19<00:14,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:24<00:09,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:28<00:04,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:33<00:00,  4.78s/it]\u001b[A\n",
      "processing results:  42%|████████▍           | 42/100 [40:17<1:04:50, 67.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:26,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:23,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:18,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:14,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:27<00:04,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:26,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:08<00:22,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:13<00:17,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:17<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:21<00:08,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:26<00:04,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:30<00:00,  4.43s/it]\u001b[A\n",
      "processing results:  43%|████████▌           | 43/100 [41:21<1:02:34, 65.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:20,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.13s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:16<00:08,  4.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.38s/it]\u001b[A\n",
      "processing results:  44%|█████████▋            | 44/100 [42:14<57:52, 62.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:34,  4.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:09<00:28,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:13<00:22,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:18<00:18,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:22<00:13,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:27<00:08,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:31<00:04,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:36<00:00,  4.57s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:18,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.58s/it]\u001b[A\n",
      "processing results:  45%|█████████▉            | 45/100 [43:18<57:24, 62.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.25s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.42s/it]\u001b[A\n",
      "processing results:  46%|██████████            | 46/100 [44:01<51:09, 56.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:25,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:08<00:22,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:18,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:17<00:13,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:22<00:08,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:26<00:04,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:30<00:00,  4.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:14,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:14<00:09,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:18<00:04,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.56s/it]\u001b[A\n",
      "processing results:  47%|██████████▎           | 47/100 [44:55<49:23, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:27,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:22,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:18,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:14,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:23<00:09,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:28<00:04,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.64s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:26,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:09<00:22,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:13<00:17,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:13,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:22<00:09,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:27<00:04,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:31<00:00,  4.52s/it]\u001b[A\n",
      "processing results:  48%|██████████▌           | 48/100 [45:59<50:36, 58.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:18,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:13,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.37s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.20s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.33s/it]\u001b[A\n",
      "processing results:  49%|██████████▊           | 49/100 [46:42<45:49, 53.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:30,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:09<00:28,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:14<00:23,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:19<00:19,  4.83s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:24<00:14,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:28<00:09,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:33<00:04,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:37<00:00,  4.69s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:34,  4.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:28,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:23,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:19<00:19,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:23<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:28<00:09,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:37<00:00,  4.63s/it]\u001b[A\n",
      "processing results:  50%|███████████           | 50/100 [47:57<50:04, 60.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:04<00:47,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:09<00:41,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:13<00:35,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:19<00:34,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:23<00:28,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:28<00:23,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:33<00:19,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:37<00:14,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:42<00:09,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:46<00:04,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:51<00:00,  4.65s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:40,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:08<00:34,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:13<00:30,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:17<00:26,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:22<00:22,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:26<00:18,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:31<00:13,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:36<00:09,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:40<00:04,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:45<00:00,  4.55s/it]\u001b[A\n",
      "processing results:  51%|███████████▏          | 51/100 [49:34<58:03, 71.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:04<00:40,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:09<00:38,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:14<00:33,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:18<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:23<00:22,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:27<00:18,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:32<00:14,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:37<00:09,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:42<00:04,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:47<00:00,  4.72s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:43,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:09<00:37,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:14<00:33,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:19<00:28,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:23<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:27<00:18,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:32<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:37<00:09,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:42<00:04,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:46<00:00,  4.68s/it]\u001b[A\n",
      "processing results:  52%|██████████▍         | 52/100 [51:08<1:02:22, 77.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:14,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.26s/it]\u001b[A\n",
      "processing results:  53%|███████████▋          | 53/100 [51:51<53:01, 67.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:05<00:45,  5.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:09<00:36,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:13<00:31,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:18<00:27,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:23<00:23,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:27<00:18,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:32<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:36<00:09,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:41<00:04,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:45<00:00,  4.60s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:42,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:09<00:38,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:13<00:32,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:18<00:27,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:23<00:23,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:27<00:18,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:32<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:36<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:41<00:04,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:46<00:00,  4.62s/it]\u001b[A\n",
      "processing results:  54%|███████████▉          | 54/100 [53:23<57:31, 75.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:19,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.55s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:23,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:17,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.61s/it]\u001b[A\n",
      "processing results:  55%|████████████          | 55/100 [54:18<51:45, 69.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:23<00:04,  4.84s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.64s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:20,  4.07s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:16<00:08,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:25<00:00,  4.27s/it]\u001b[A\n",
      "processing results:  56%|████████████▎         | 56/100 [55:12<47:11, 64.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:05<00:42,  5.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:32,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:13<00:27,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:22,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:22<00:17,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:27<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:31<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:35<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:39<00:00,  4.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:35,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:08<00:30,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:26,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:17<00:21,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:22<00:17,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:26<00:13,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:31<00:09,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:36<00:04,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:40<00:00,  4.54s/it]\u001b[A\n",
      "processing results:  57%|████████████▌         | 57/100 [56:32<49:36, 69.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:20,  4.18s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:16<00:08,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:25<00:00,  4.30s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:23,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.50s/it]\u001b[A\n",
      "processing results:  58%|████████████▊         | 58/100 [57:25<45:00, 64.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:28,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:09<00:23,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:18,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:18<00:13,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:22<00:08,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:27<00:04,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:32<00:00,  4.61s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:05<00:25,  5.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:19,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:14<00:13,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.51s/it]\u001b[A\n",
      "processing results:  59%|████████████▉         | 59/100 [58:25<42:55, 62.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:16,  4.20s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:09,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:25<00:00,  4.33s/it]\u001b[A\n",
      "processing results:  60%|█████████████▏        | 60/100 [59:17<39:50, 59.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:09,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:23<00:04,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.60s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:05<00:26,  5.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:19,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:14<00:14,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:23<00:04,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.64s/it]\u001b[A\n",
      "processing results:  61%|████████████▏       | 61/100 [1:00:13<37:59, 58.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:23,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:09,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:18<00:04,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.59s/it]\u001b[A\n",
      "processing results:  62%|████████████▍       | 62/100 [1:01:02<35:16, 55.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:04<00:49,  4.97s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:09<00:41,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:13<00:36,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:18<00:32,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:23<00:27,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:27<00:23,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:32<00:18,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:37<00:14,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:41<00:09,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:46<00:04,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:51<00:00,  4.68s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:38,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:09<00:33,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:14<00:29,  4.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:19<00:24,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:23<00:18,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:28<00:14,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:33<00:09,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:38<00:04,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:43<00:00,  4.79s/it]\u001b[A\n",
      "processing results:  63%|████████████▌       | 63/100 [1:02:37<41:33, 67.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:21,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:23<00:04,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.52s/it]\u001b[A\n",
      "processing results:  64%|████████████▊       | 64/100 [1:03:30<37:57, 63.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:04<00:46,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:09<00:41,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:14<00:37,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:18<00:32,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:23<00:29,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:28<00:24,  4.85s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:33<00:18,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:38<00:14,  4.84s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:42<00:09,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:47<00:04,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:52<00:00,  4.81s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:34,  4.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:09<00:32,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:18<00:23,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:22<00:18,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:27<00:13,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:31<00:09,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:36<00:04,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:41<00:00,  4.56s/it]\u001b[A\n",
      "processing results:  65%|█████████████       | 65/100 [1:05:04<42:16, 72.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:20,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:10<00:20,  5.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:14<00:14,  4.85s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:19<00:09,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:24<00:04,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:28<00:00,  4.78s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:20,  4.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.42s/it]\u001b[A\n",
      "processing results:  66%|█████████████▏      | 66/100 [1:05:59<38:08, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:27<00:00,  4.58s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.13s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.27s/it]\u001b[A\n",
      "processing results:  67%|█████████████▍      | 67/100 [1:06:48<33:58, 61.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.40s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n",
      "processing results:  68%|█████████████▌      | 68/100 [1:07:32<30:01, 56.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.22s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n",
      "processing results:  69%|█████████████▊      | 69/100 [1:08:14<26:57, 52.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:38,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:34,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:14<00:27,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:18<00:23,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:23<00:18,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:27<00:13,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:32<00:09,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:36<00:04,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:41<00:00,  4.56s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:30,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:08<00:26,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:13<00:21,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:17<00:17,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:22<00:13,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:27<00:09,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.83s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:37<00:00,  4.70s/it]\u001b[A\n",
      "processing results:  70%|██████████████      | 70/100 [1:09:33<30:03, 60.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:24,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:18,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.56s/it]\u001b[A\n",
      "processing results:  71%|██████████████▏     | 71/100 [1:10:27<28:08, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:20,  4.12s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.44s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:24,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:19,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:14<00:14,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.56s/it]\u001b[A\n",
      "processing results:  72%|██████████████▍     | 72/100 [1:11:21<26:34, 56.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:18,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:13,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.46s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:03<00:15,  3.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.11s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.37s/it]\u001b[A\n",
      "processing results:  73%|██████████████▌     | 73/100 [1:12:05<23:53, 53.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:31,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:08<00:26,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:13<00:21,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:18<00:18,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:23<00:14,  4.85s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:27<00:09,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:32<00:04,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:36<00:00,  4.61s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:25,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:09<00:22,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:13<00:18,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:13,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:22<00:09,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:27<00:04,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:31<00:00,  4.55s/it]\u001b[A\n",
      "processing results:  74%|██████████████▊     | 74/100 [1:13:14<25:02, 57.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:04<00:53,  4.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:09<00:46,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:14<00:41,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:18<00:36,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:22<00:30,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:27<00:27,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:31<00:22,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:36<00:18,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:40<00:13,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:45<00:08,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:49<00:04,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:53<00:00,  4.48s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:37,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:08<00:34,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:13<00:32,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:18<00:27,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:22<00:22,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:27<00:18,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:31<00:13,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:36<00:08,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:40<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:45<00:00,  4.55s/it]\u001b[A\n",
      "processing results:  75%|███████████████     | 75/100 [1:14:53<29:15, 70.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:18,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:14,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.57s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:05<00:22,  5.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:09<00:14,  4.85s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:14<00:09,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:18<00:04,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:23<00:00,  4.60s/it]\u001b[A\n",
      "processing results:  76%|███████████████▏    | 76/100 [1:15:39<25:10, 62.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/33 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   3%|▋                       | 1/33 [00:05<03:09,  5.93s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   6%|█▍                      | 2/33 [00:12<03:06,  6.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 3/33 [00:17<02:53,  5.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|██▉                     | 4/33 [00:23<02:50,  5.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 5/33 [00:30<02:51,  6.12s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 6/33 [00:36<02:50,  6.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  21%|█████                   | 7/33 [00:42<02:40,  6.17s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  24%|█████▊                  | 8/33 [00:48<02:32,  6.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 9/33 [00:54<02:24,  6.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|██████▉                | 10/33 [01:00<02:19,  6.07s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|███████▋               | 11/33 [01:06<02:11,  6.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▎              | 12/33 [01:12<02:05,  5.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  39%|█████████              | 13/33 [01:18<02:01,  6.06s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|█████████▊             | 14/33 [01:24<01:54,  6.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▍            | 15/33 [01:30<01:47,  6.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  48%|███████████▏           | 16/33 [01:36<01:44,  6.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  52%|███████████▊           | 17/33 [01:42<01:36,  6.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|████████████▌          | 18/33 [01:48<01:29,  5.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|█████████████▏         | 19/33 [01:54<01:22,  5.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  61%|█████████████▉         | 20/33 [02:00<01:16,  5.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|██████████████▋        | 21/33 [02:06<01:10,  5.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|███████████████▎       | 22/33 [02:11<01:04,  5.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████       | 23/33 [02:17<00:57,  5.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|████████████████▋      | 24/33 [02:23<00:51,  5.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  76%|█████████████████▍     | 25/33 [02:29<00:46,  5.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  79%|██████████████████     | 26/33 [02:35<00:41,  5.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|██████████████████▊    | 27/33 [02:41<00:35,  5.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▌   | 28/33 [02:47<00:30,  6.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|████████████████████▏  | 29/33 [02:53<00:23,  5.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 30/33 [02:58<00:17,  5.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  94%|█████████████████████▌ | 31/33 [03:04<00:11,  5.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  97%|██████████████████████▎| 32/33 [03:10<00:05,  5.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 33/33 [03:17<00:00,  5.98s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/29 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   3%|▋                   | 1/29 [00:05<02:32,  5.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   7%|█▍                  | 2/29 [00:11<02:34,  5.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 3/29 [00:17<02:29,  5.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|██▊                 | 4/29 [00:23<02:24,  5.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▍                | 5/29 [00:29<02:29,  6.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  21%|████▏               | 6/29 [00:36<02:21,  6.16s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  24%|████▊               | 7/29 [00:41<02:13,  6.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  28%|█████▌              | 8/29 [00:48<02:10,  6.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  31%|██████▏             | 9/29 [00:54<02:02,  6.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  34%|██████▌            | 10/29 [01:00<01:55,  6.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▏           | 11/29 [01:06<01:47,  5.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  41%|███████▊           | 12/29 [01:11<01:40,  5.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|████████▌          | 13/29 [01:17<01:34,  5.89s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  48%|█████████▏         | 14/29 [01:23<01:27,  5.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  52%|█████████▊         | 15/29 [01:29<01:21,  5.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▍        | 16/29 [01:35<01:18,  6.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  59%|███████████▏       | 17/29 [01:41<01:10,  5.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|███████████▊       | 18/29 [01:46<01:03,  5.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  66%|████████████▍      | 19/29 [01:52<00:57,  5.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  69%|█████████████      | 20/29 [01:59<00:54,  6.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  72%|█████████████▊     | 21/29 [02:05<00:48,  6.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  76%|██████████████▍    | 22/29 [02:10<00:41,  5.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  79%|███████████████    | 23/29 [02:17<00:36,  6.05s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|███████████████▋   | 24/29 [02:22<00:28,  5.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|████████████████▍  | 25/29 [02:28<00:23,  5.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|█████████████████  | 26/29 [02:34<00:17,  5.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  93%|█████████████████▋ | 27/29 [02:40<00:11,  5.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  97%|██████████████████▎| 28/29 [02:46<00:05,  5.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 29/29 [02:51<00:00,  5.93s/it]\u001b[A\n",
      "processing results:  77%|██████████████▋    | 77/100 [1:21:48<59:20, 154.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:20,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.42s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:03<00:19,  3.98s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:17,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:13,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.33s/it]\u001b[A\n",
      "processing results:  78%|██████████████▊    | 78/100 [1:22:41<45:31, 124.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.02s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.23s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:13,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:08<00:08,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:12<00:04,  4.26s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:17<00:00,  4.34s/it]\u001b[A\n",
      "processing results:  79%|███████████████▊    | 79/100 [1:23:19<34:27, 98.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:04<00:51,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:09<00:47,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:14<00:41,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:18<00:37,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:23<00:32,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:28<00:27,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:32<00:23,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:37<00:19,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:42<00:14,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:46<00:09,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:51<00:04,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:56<00:00,  4.68s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   8%|█▋                  | 1/12 [00:05<00:55,  5.03s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▎                | 2/12 [00:10<00:51,  5.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████               | 3/12 [00:15<00:44,  4.99s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|██████▋             | 4/12 [00:19<00:39,  4.92s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  42%|████████▎           | 5/12 [00:24<00:33,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 6/12 [00:28<00:28,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  58%|███████████▋        | 7/12 [00:33<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|█████████████▎      | 8/12 [00:38<00:18,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████     | 9/12 [00:43<00:14,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|███████████████▊   | 10/12 [00:47<00:09,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  92%|█████████████████▍ | 11/12 [00:52<00:04,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 12/12 [00:56<00:00,  4.69s/it]\u001b[A\n",
      "processing results:  80%|███████████████▏   | 80/100 [1:25:12<34:12, 102.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.37s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:22,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:09<00:18,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:13<00:12,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:17<00:08,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:22<00:04,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.45s/it]\u001b[A\n",
      "processing results:  81%|████████████████▏   | 81/100 [1:26:05<27:46, 87.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.25s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:20<00:00,  4.20s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:18,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:13,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.35s/it]\u001b[A\n",
      "processing results:  82%|████████████████▍   | 82/100 [1:26:47<22:16, 74.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.12s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:20<00:00,  4.19s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:13,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:08<00:08,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:13<00:04,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:17<00:00,  4.45s/it]\u001b[A\n",
      "processing results:  83%|████████████████▌   | 83/100 [1:27:26<18:01, 63.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:09<00:14,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:08,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:17<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.32s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.08s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.38s/it]\u001b[A\n",
      "processing results:  84%|████████████████▊   | 84/100 [1:28:10<15:21, 57.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  11%|██▊                      | 1/9 [00:04<00:38,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  22%|█████▌                   | 2/9 [00:09<00:34,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 3/9 [00:15<00:32,  5.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  44%|███████████              | 4/9 [00:20<00:25,  5.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  56%|█████████████▉           | 5/9 [00:25<00:19,  4.95s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 6/9 [00:29<00:14,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  78%|███████████████████▍     | 7/9 [00:34<00:09,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  89%|██████████████████████▏  | 8/9 [00:38<00:04,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 9/9 [00:43<00:00,  4.87s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:31,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:28,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:23,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:18<00:18,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:23<00:13,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:27<00:09,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:36<00:00,  4.60s/it]\u001b[A\n",
      "processing results:  85%|█████████████████   | 85/100 [1:29:30<16:07, 64.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/13 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|█▊                      | 1/13 [00:04<00:55,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  15%|███▋                    | 2/13 [00:09<00:49,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  23%|█████▌                  | 3/13 [00:13<00:46,  4.67s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  31%|███████▍                | 4/13 [00:18<00:42,  4.72s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▏              | 5/13 [00:23<00:36,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  46%|███████████             | 6/13 [00:27<00:32,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  54%|████████████▉           | 7/13 [00:32<00:28,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|██████████████▊         | 8/13 [00:37<00:23,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  69%|████████████████▌       | 9/13 [00:41<00:18,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  77%|█████████████████▋     | 10/13 [00:46<00:13,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  85%|███████████████████▍   | 11/13 [00:51<00:09,  4.77s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████▏ | 12/13 [00:57<00:05,  5.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 13/13 [01:01<00:00,  4.75s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:04<00:48,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:09<00:43,  4.81s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:14<00:36,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:18<00:32,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:23<00:28,  4.78s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:28<00:23,  4.75s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:33<00:18,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:38<00:14,  4.83s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:42<00:09,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:47<00:04,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:52<00:00,  4.75s/it]\u001b[A\n",
      "processing results:  86%|█████████████████▏  | 86/100 [1:31:24<18:30, 79.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:04<00:46,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:08<00:38,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:13<00:34,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:18<00:32,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:22<00:27,  4.60s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:27<00:23,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:32<00:19,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:36<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:41<00:09,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:46<00:04,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:50<00:00,  4.61s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  12%|██▋                  | 1/8 [00:04<00:34,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 2/8 [00:09<00:29,  4.87s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  38%|███████▉             | 3/8 [00:14<00:23,  4.70s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 4/8 [00:18<00:18,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  62%|█████████████▏       | 5/8 [00:23<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 6/8 [00:27<00:09,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  88%|██████████████████▍  | 7/8 [00:32<00:04,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 8/8 [00:36<00:00,  4.62s/it]\u001b[A\n",
      "processing results:  87%|█████████████████▍  | 87/100 [1:32:52<17:44, 81.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.33s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:20,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:18,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:18<00:09,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:23<00:04,  4.80s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:27<00:00,  4.61s/it]\u001b[A\n",
      "processing results:  88%|█████████████████▌  | 88/100 [1:33:46<14:40, 73.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/8 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  12%|███▏                     | 1/8 [00:04<00:29,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████▎                  | 2/8 [00:08<00:25,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  38%|█████████▍               | 3/8 [00:13<00:22,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 4/8 [00:17<00:18,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  62%|███████████████▋         | 5/8 [00:22<00:13,  4.47s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████▊      | 6/8 [00:26<00:08,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  88%|█████████████████████▉   | 7/8 [00:31<00:04,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 8/8 [00:36<00:00,  4.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:28,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:08<00:21,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:13<00:17,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:13,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:22<00:09,  4.54s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:28<00:04,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:32<00:00,  4.65s/it]\u001b[A\n",
      "processing results:  89%|█████████████████▊  | 89/100 [1:34:54<13:12, 72.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:26,  4.39s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:08<00:21,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:13<00:17,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:17<00:13,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:22<00:09,  4.53s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:27<00:04,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:31<00:00,  4.53s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.36s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.29s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n",
      "processing results:  90%|██████████████████  | 90/100 [1:35:48<11:03, 66.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.48s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:16<00:04,  4.13s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:21<00:00,  4.23s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.38s/it]\u001b[A\n",
      "processing results:  91%|██████████████████▏ | 91/100 [1:36:31<08:54, 59.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  10%|██▍                     | 1/10 [00:04<00:39,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|████▊                   | 2/10 [00:09<00:39,  4.96s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  30%|███████▏                | 3/10 [00:14<00:32,  4.71s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|█████████▌              | 4/10 [00:18<00:27,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 5/10 [00:23<00:22,  4.59s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|██████████████▍         | 6/10 [00:27<00:17,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  70%|████████████████▊       | 7/10 [00:32<00:14,  4.73s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|███████████████████▏    | 8/10 [00:37<00:09,  4.79s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  90%|█████████████████████▌  | 9/10 [00:42<00:04,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 10/10 [00:46<00:00,  4.66s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/9 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  11%|██▎                  | 1/9 [00:04<00:36,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  22%|████▋                | 2/9 [00:09<00:32,  4.58s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 3/9 [00:13<00:27,  4.57s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  44%|█████████▎           | 4/9 [00:18<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  56%|███████████▋         | 5/9 [00:22<00:18,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 6/9 [00:27<00:13,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  78%|████████████████▎    | 7/9 [00:31<00:09,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  89%|██████████████████▋  | 8/9 [00:36<00:04,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 9/9 [00:40<00:00,  4.50s/it]\u001b[A\n",
      "processing results:  92%|██████████████████▍ | 92/100 [1:37:58<09:01, 67.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:23,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:12,  4.28s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.41s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.63s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.45s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/4 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  25%|█████▎               | 1/4 [00:04<00:13,  4.44s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 2/4 [00:08<00:08,  4.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  75%|███████████████▊     | 3/4 [00:12<00:04,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 4/4 [00:17<00:00,  4.26s/it]\u001b[A\n",
      "processing results:  93%|██████████████████▌ | 93/100 [1:38:42<07:03, 60.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  14%|███▌                     | 1/7 [00:04<00:25,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  29%|███████▏                 | 2/7 [00:08<00:20,  4.19s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  43%|██████████▋              | 3/7 [00:12<00:17,  4.34s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  57%|██████████████▎          | 4/7 [00:17<00:13,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  71%|█████████████████▊       | 5/7 [00:21<00:08,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  86%|█████████████████████▍   | 6/7 [00:26<00:04,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 7/7 [00:30<00:00,  4.31s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/7 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  14%|███                  | 1/7 [00:04<00:26,  4.43s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  29%|██████               | 2/7 [00:08<00:21,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  43%|█████████            | 3/7 [00:12<00:17,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  57%|████████████         | 4/7 [00:18<00:13,  4.66s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  71%|███████████████      | 5/7 [00:22<00:09,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  86%|██████████████████   | 6/7 [00:27<00:04,  4.55s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 7/7 [00:31<00:00,  4.49s/it]\u001b[A\n",
      "processing results:  94%|██████████████████▊ | 94/100 [1:39:43<06:05, 60.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   9%|██▏                     | 1/11 [00:04<00:46,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  18%|████▎                   | 2/11 [00:08<00:39,  4.38s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  27%|██████▌                 | 3/11 [00:13<00:36,  4.56s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  36%|████████▋               | 4/11 [00:18<00:32,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  45%|██████████▉             | 5/11 [00:22<00:27,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  55%|█████████████           | 6/11 [00:27<00:22,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  64%|███████████████▎        | 7/11 [00:31<00:17,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  73%|█████████████████▍      | 8/11 [00:36<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  82%|███████████████████▋    | 9/11 [00:41<00:09,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  91%|████████████████████▉  | 10/11 [00:46<00:04,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 11/11 [00:51<00:00,  4.66s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/11 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:   9%|█▊                  | 1/11 [00:04<00:44,  4.50s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  18%|███▋                | 2/11 [00:08<00:38,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  27%|█████▍              | 3/11 [00:13<00:37,  4.69s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  36%|███████▎            | 4/11 [00:18<00:33,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  45%|█████████           | 5/11 [00:23<00:27,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  55%|██████████▉         | 6/11 [00:27<00:23,  4.65s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  64%|████████████▋       | 7/11 [00:32<00:18,  4.64s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  73%|██████████████▌     | 8/11 [00:36<00:13,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  82%|████████████████▎   | 9/11 [00:41<00:09,  4.62s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  91%|█████████████████▎ | 10/11 [00:45<00:04,  4.52s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 11/11 [00:50<00:00,  4.56s/it]\u001b[A\n",
      "processing results:  95%|███████████████████ | 95/100 [1:41:25<06:05, 73.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:22,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:09<00:18,  4.61s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:13<00:13,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:18<00:09,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:22<00:04,  4.40s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:26<00:00,  4.39s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  17%|███▌                 | 1/6 [00:04<00:22,  4.45s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  33%|███████              | 2/6 [00:08<00:16,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████▌          | 3/6 [00:12<00:12,  4.27s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  67%|██████████████       | 4/6 [00:16<00:08,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  83%|█████████████████▌   | 5/6 [00:21<00:04,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 6/6 [00:26<00:00,  4.35s/it]\u001b[A\n",
      "processing results:  96%|███████████████████▏| 96/100 [1:42:17<04:27, 66.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:17,  4.37s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:13,  4.46s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:13<00:09,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.49s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.41s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:16,  4.23s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.27s/it]\u001b[A\n",
      "processing results:  97%|███████████████████▍| 97/100 [1:43:00<02:59, 59.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                | 0/12 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:   8%|██                      | 1/12 [00:05<00:59,  5.42s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████                    | 2/12 [00:10<00:52,  5.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  25%|██████                  | 3/12 [00:15<00:44,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████                | 4/12 [00:20<00:40,  5.01s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  42%|██████████              | 5/12 [00:25<00:34,  5.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████            | 6/12 [00:30<00:30,  5.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  58%|██████████████          | 7/12 [00:34<00:24,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████        | 8/12 [00:39<00:19,  4.88s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  75%|██████████████████      | 9/12 [00:44<00:14,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|███████████████████▏   | 10/12 [00:48<00:09,  4.74s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  92%|█████████████████████  | 11/12 [00:54<00:04,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|███████████████████████| 12/12 [00:59<00:00,  4.95s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                            | 0/10 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  10%|██                  | 1/10 [00:04<00:43,  4.85s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████                | 2/10 [00:09<00:37,  4.68s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  30%|██████              | 3/10 [00:14<00:34,  4.86s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████            | 4/10 [00:19<00:29,  4.94s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  50%|██████████          | 5/10 [00:24<00:25,  5.04s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████        | 6/10 [00:29<00:19,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  70%|██████████████      | 7/10 [00:34<00:14,  4.90s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████    | 8/10 [00:39<00:09,  4.91s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  90%|██████████████████  | 9/10 [00:43<00:04,  4.82s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|███████████████████| 10/10 [00:48<00:00,  4.86s/it]\u001b[A\n",
      "processing results:  98%|███████████████████▌| 98/100 [1:44:48<02:28, 74.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  20%|█████                    | 1/5 [00:04<00:16,  4.15s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  40%|██████████               | 2/5 [00:08<00:12,  4.10s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  60%|███████████████          | 3/5 [00:12<00:08,  4.09s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  80%|████████████████████     | 4/5 [00:18<00:04,  4.76s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 5/5 [00:22<00:00,  4.43s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:03<00:15,  4.00s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.14s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:12<00:08,  4.24s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:16<00:04,  4.22s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:21<00:00,  4.30s/it]\u001b[A\n",
      "processing results:  99%|███████████████████▊| 99/100 [1:45:32<01:05, 65.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "processing y_stars:   0%|                                 | 0/6 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  17%|████▏                    | 1/6 [00:04<00:21,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  33%|████████▎                | 2/6 [00:08<00:17,  4.30s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  50%|████████████▌            | 3/6 [00:12<00:12,  4.21s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  67%|████████████████▋        | 4/6 [00:17<00:08,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars:  83%|████████████████████▊    | 5/6 [00:21<00:04,  4.31s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_stars: 100%|█████████████████████████| 6/6 [00:25<00:00,  4.30s/it]\u001b[A\n",
      "\n",
      "processing y_non_stars:   0%|                             | 0/5 [00:00<?, ?it/s]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  20%|████▏                | 1/5 [00:04<00:17,  4.33s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  40%|████████▍            | 2/5 [00:08<00:12,  4.32s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  60%|████████████▌        | 3/5 [00:13<00:08,  4.35s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars:  80%|████████████████▊    | 4/5 [00:17<00:04,  4.51s/it]\u001b[ASpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\n",
      "processing y_non_stars: 100%|█████████████████████| 5/5 [00:22<00:00,  4.51s/it]\u001b[A\n",
      "processing results: 100%|███████████████████| 100/100 [1:46:20<00:00, 63.81s/it]\n"
     ]
    }
   ],
   "source": [
    "add_model_probs(all_model_probs, client, world_model_endpoints, [], model_type='world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7061b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'target_token_probs_train_{id}_10_epochs_with_prompt_higher_with_shadow_with_world.json', 'w') as f:\n",
    "    json.dump(all_model_probs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "267e9741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nausea': {'target': 0.030567360182921947,\n",
       "  'prompt': 'consider someone with the following conditions:  vomiting, headache, lightheadedness, dizziness, migraine, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.028715377451561396],\n",
       "  'world_models': [0.00012023269569472103,\n",
       "   0.014717029298635137,\n",
       "   0.002230635515235311]},\n",
       " 'vomiting': {'target': 0.025341231657550464,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, headache, lightheadedness, dizziness, migraine, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.019735771058894177],\n",
       "  'world_models': [0.0013678549324438345,\n",
       "   0.017205950425851383,\n",
       "   0.001354415441799287]},\n",
       " 'headache': {'target': 0.008757695319760317,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, vomiting, lightheadedness, dizziness, migraine, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.009923768904016987],\n",
       "  'world_models': [0.005925295439484114,\n",
       "   0.005763271481312824,\n",
       "   2.1487334273037496e-05]},\n",
       " 'lightheadedness': {'target': 0.0009569326986862334,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, vomiting, headache, dizziness, migraine, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.0006202366797206253],\n",
       "  'world_models': [2.048145943195609e-06,\n",
       "   0.0006456795567848394,\n",
       "   9.2277829383876e-05]},\n",
       " 'dizziness': {'target': 0.0067699657578189415,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, vomiting, headache, lightheadedness, migraine, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.008175222462752187],\n",
       "  'world_models': [7.234864162275087e-06,\n",
       "   0.012322082451580453,\n",
       "   0.003477287172964511]},\n",
       " 'migraine': {'target': 0.000982586183001675,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, vomiting, headache, lightheadedness, dizziness, Morphine . the individual then also has the condition ',\n",
       "  'shadow_models': [0.0010459575472145327],\n",
       "  'world_models': [6.209412804107607e-05,\n",
       "   0.0006671470977542673,\n",
       "   0.00014350780987923558]},\n",
       " 'Morphine': {'target': 4.626401845945086e-06,\n",
       "  'prompt': 'consider someone with the following conditions:  nausea, vomiting, headache, lightheadedness, dizziness, migraine . the individual then also has the condition ',\n",
       "  'shadow_models': [3.8061623597740873e-06],\n",
       "  'world_models': [2.59538440072069e-09,\n",
       "   1.3689000953369672e-06,\n",
       "   2.914987308245765e-09]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_probs['train_1']['y_stars']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

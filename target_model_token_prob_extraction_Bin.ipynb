{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ca44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binhan/anaconda3/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from together import Together\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from utils import *\n",
    "from huggingface_hub import login as hf_login\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from datasets import concatenate_datasets, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b821c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/binhan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open('model_map.json') as f:\n",
    "    model_map=json.load(f)\n",
    "key = '779d92de61a5035835e5023ca79e2e5b6124c6300c3ceb0e07e374f948554116'\n",
    "client = Together(api_key=key)\n",
    "hf_login(token=\"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\")\n",
    "dataset = load_dataset(\"beanham/medsum_llm_attack\")\n",
    "merged_dataset = concatenate_datasets([dataset['train'], dataset['validation'], dataset['test']])\n",
    "new_ids = range(len(merged_dataset))\n",
    "merged_dataset = merged_dataset.add_column(\"new_ID\", new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "split='train'\n",
    "id='2'\n",
    "\n",
    "## load model\n",
    "target_model_api_key=\"bh193/Meta-Llama-3.1-8B-Instruct-Reference-2104a2dc-d23b5213\"\n",
    "prob_generator = GenerateNextTokenProbAPI(client, target_model_api_key)\n",
    "\n",
    "## load data\n",
    "target_subsample_ids = pd.read_csv(f\"formatted_data/subsample_ids_{id}.csv\")['new_ID'].tolist()\n",
    "train_dataset = merged_dataset.filter(lambda example: example['new_ID'] in target_subsample_ids)\n",
    "test_dataset = merged_dataset.filter(lambda example: example['new_ID'] not in target_subsample_ids)\n",
    "\n",
    "## why are we only using len(ents)<5 as the unseen ents?\n",
    "unseen_ents = [sample['disease_ents'] for sample in test_dataset if len(sample['disease_ents']) < 5]\n",
    "unseen_ents = [item for sublist in unseen_ents for item in sublist]\n",
    "\n",
    "train_dataset = [sample for sample in train_dataset if len(sample['disease_ents']) >= 5]\n",
    "test_dataset = [sample for sample in test_dataset if len(sample['disease_ents']) >= 5]\n",
    "train_test_ents = {'train': train_dataset,'test': test_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da25825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 145, 'bh193/Meta-Llama-3.1-8B-Instruct-Reference-2104a2dc-d23b5213')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), target_model_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14024df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████████████████▊                                                                                                                                                       | 1/10 [00:02<00:22,  2.46s/it]\u001b[A\n",
      " 20%|█████████████████████████████████▌                                                                                                                                      | 2/10 [00:04<00:17,  2.16s/it]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▍                                                                                                                     | 3/10 [00:06<00:15,  2.20s/it]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▏                                                                                                    | 4/10 [00:07<00:11,  1.86s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████                                                                                    | 5/10 [00:10<00:09,  1.96s/it]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                   | 6/10 [00:12<00:08,  2.03s/it]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 7/10 [00:14<00:06,  2.09s/it]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 8/10 [00:16<00:04,  2.19s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 9/10 [00:19<00:02,  2.18s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.02s/it]\u001b[A\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 1/5 [00:20<01:20, 20.18s/it]\n",
      "  0%|                                                                                                                                                                                 | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|████████████████████████████▏                                                                                                                                            | 1/6 [00:01<00:06,  1.37s/it]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 2/6 [00:02<00:05,  1.44s/it]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3/6 [00:04<00:04,  1.43s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 4/6 [00:05<00:02,  1.39s/it]\u001b[A\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 5/6 [00:07<00:01,  1.53s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.47s/it]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 2/5 [00:28<00:40, 13.49s/it]\n",
      "  0%|                                                                                                                                                                                 | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▊                                                                                                                                       | 1/5 [00:00<00:03,  1.02it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 2/5 [00:25<00:44, 14.85s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 3/5 [02:50<01:53, 56.90s/it]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 2/5 [03:19<04:59, 99.84s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "fail_counter = 0\n",
    "# get first 50 pairs from train_test_ents \n",
    "\n",
    "for name, samples in train_test_ents.items():\n",
    "    \n",
    "    for ent_list in tqdm(samples[:5]):\n",
    "        \n",
    "        ## create saving dictionary\n",
    "        key=name+'_'+str(ent_list['ID'])\n",
    "        results[key]={}\n",
    "        results[key]['y_stars']={}\n",
    "        results[key]['y_NON_stars']={}        \n",
    "        ents = list(set(ent_list['disease_ents']))\n",
    "        k = len(ents)\n",
    "        unseen_ents_for_sample = random.sample(unseen_ents, k)\n",
    "        \n",
    "        ## go through each y_star\n",
    "        for i in tqdm(range(k)):\n",
    "            \n",
    "            y_star = ents[i]\n",
    "            y_NON_star = unseen_ents_for_sample[i]\n",
    "            results[key]['y_stars'][y_star]={}\n",
    "            results[key]['y_NON_stars'][y_NON_star]={}                        \n",
    "            remaining_ents = ents[:i] + ents[i + 1:]            \n",
    "            \n",
    "            # prompt = f\"consider someone with the following conditions: {', '.join(remaining_ents)}. the individual then also has the condition \"\n",
    "            prompt_start = PROMPT_TEMPLATE[PROMPT_TO_USE][0]\n",
    "            prompt_end = PROMPT_TEMPLATE[PROMPT_TO_USE][1]\n",
    "            ents_string = ', '.join(remaining_ents)\n",
    "            prompt = f\"{prompt_start} {ents_string} {prompt_end}\"\n",
    "\n",
    "            #print(prompt)\n",
    "\n",
    "            prob = compute_token_probs_api(y_star, prompt, prob_generator) \n",
    "            prob_NON = compute_token_probs_api(y_NON_star, prompt, prob_generator)            \n",
    "            if prob == -1 or prob_NON == -1:\n",
    "                fail_counter += 1\n",
    "                print(f\"failed {fail_counter} times\")\n",
    "                continue            \n",
    "            results[key]['y_stars'][y_star]['target']=prob\n",
    "            results[key]['y_NON_stars'][y_NON_star]['target']=prob_NON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc621fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'target_token_probs_{split}_{id}_10_epochs.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
